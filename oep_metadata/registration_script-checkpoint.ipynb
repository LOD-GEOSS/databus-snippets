{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following definition filters table URLs out of the schema pages\n",
    "# There's most likely a smarter way of doing this.\n",
    "# Also, I should probably learn list comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables(schema):\n",
    "    schema_url = 'https://openenergy-platform.org/dataedit/view/' + schema\n",
    "    with urllib.request.urlopen(schema_url) as f:\n",
    "        html = f.read().decode('utf-8')\n",
    "    urls = []\n",
    "    prefix = \"https://openenergy-platform.org\"\n",
    "    for line in html.splitlines():\n",
    "        pattern = \"onclick\"\n",
    "        if re.search(pattern, line):\n",
    "            url_line = line.split(\"'\")\n",
    "            for i in url_line:\n",
    "                if 'dataedit' in i:\n",
    "                    urls.append(prefix + i)\n",
    "    return(urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:997)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\http\\client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\http\\client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\http\\client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\http\\client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m \n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\http\\client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\http\\client.py:1454\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\ssl.py:512\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    507\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    509\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\ssl.py:1070\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1070\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\ssl.py:1341\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1341\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:997)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m schema_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://openenergy-platform.org/dataedit/view/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#+ 'boundaries'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(schema_url) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     html \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(html)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\d_pylatest_datascience\\lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:997)>"
     ]
    }
   ],
   "source": [
    "schema_url = 'https://openenergy-platform.org/dataedit/view/' + 'boundaries'\n",
    "with urllib.request.urlopen(schema_url) as f:\n",
    "    html = f.read().decode('utf-8')\n",
    "print(html)\n",
    "urls = []\n",
    "prefix = \"https://openenergy-platform.org\"\n",
    "for line in html.splitlines():\n",
    "    pattern = \"onclick\"\n",
    "    if re.search(pattern, line):\n",
    "        url_line = line.split(\"'\")\n",
    "        for i in url_line:\n",
    "            if 'dataedit' in i:\n",
    "                urls.append(prefix + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_urls = get_tables('boundaries')\n",
    "print(table_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL overview:\n",
    "# table view url:\n",
    "#     'https://openenergy-platform.org/dataedit/view/schema/tablename']\n",
    "# download actual table:\n",
    "#     https://openenergy-platform.org/api/v0/schema/boundaries/tables/bkg_vg250_6_gem/rows?form=csv\n",
    "# download table metadata:\n",
    "#     https://openenergy-platform.org/api/v0/schema/boundaries/tables/bkg_vg250_6_gem/meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_schemas: [\n",
    "    \"boundaries\",\n",
    "    \"climate\",\n",
    "    \"demand\",\n",
    "    \"economy\",\n",
    "    \"environment\",\n",
    "    \"grid\",\n",
    "    \"model_draft\",\n",
    "    \"openstreetmap\",\n",
    "    \"policy\",\n",
    "    \"reference\",\n",
    "    \"scenario\",\n",
    "    \"society\",\n",
    "    \"supply\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates link to a table's metadata from its view url\n",
    "def get_table_meta_url(table_view_url):\n",
    "    url_parts = table_view_url.split('/')\n",
    "    schema = url_parts[5]\n",
    "    tablename = url_parts[6]\n",
    "    metalink = 'https://openenergy-platform.org/api/v0/schema/{0}/tables/{1}/meta'.format(schema, tablename)\n",
    "    return(metalink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns table's metadata\n",
    "def get_table_meta(table_view_url):\n",
    "    meta_url = get_table_meta_url(table_view_url)\n",
    "    with urllib.request.urlopen(meta_url) as f:\n",
    "        html = f.read().decode('utf-8')\n",
    "    return(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting metadatata function test\n",
    "testtable = 'https://openenergy-platform.org/dataedit/view/boundaries/bkg_vg250_6_gem'\n",
    "meta = json.loads(get_table_meta(testtable))\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through json, which is a nested dictionary with lists \n",
    "# to unnest keys\n",
    "# recursive function with global dictionary. Probably better ways to do this,\n",
    "\n",
    "globaldict = {}\n",
    "def loopkey(d, prefix):\n",
    "    for k in d:\n",
    "        if type(d[k]) == dict:\n",
    "            loopkey(d[k], prefix + k + \"_\")\n",
    "        elif type(d[k]) == list and type(d[k][0]) == dict:\n",
    "            # if there is a dict in a list, enumerate the contents\n",
    "            for idx, val in enumerate(d[k]):\n",
    "                # skip the zero, probably smarter approaches exist\n",
    "                if idx == 0:\n",
    "                    loopkey(val, prefix + k + \"_\")\n",
    "                else:\n",
    "                    loopkey(val, prefix + k + str(idx) + \"_\")\n",
    "        else:\n",
    "            if d[k] == 'none':\n",
    "                continue\n",
    "            #print(prefix + k + \": \"+str(d[k]))\n",
    "            key = prefix + k\n",
    "            globaldict[key] = str(d[k])\n",
    "    return(globaldict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function and reset globaldict\n",
    "loopkey(meta, '')\n",
    "print(globaldict)\n",
    "globaldict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check which tables have metadata at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API registration\n",
    "The rest of this jupyter notebook is adapted from Denis. At this current state it's not working. It's missing a password. Also it might need to be changed to work with the new databus (ask Leipzig). However, if it can be turned into a function, the resources above ahould be sufficient to automatically register all tables from the OEP.\n",
    "\n",
    "see: https://github.com/LOD-GEOSS/databus-snippets/blob/master/databus_api_examples/api_example_ks95.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataGroup:\n",
    "    account_name: str\n",
    "    id: str\n",
    "    label: str\n",
    "    title: str\n",
    "    comment: str\n",
    "    abstract: str\n",
    "    description: str\n",
    "    context: str = \"https://raw.githubusercontent.com/dbpedia/databus-git-mockup/main/dev/context.jsonld\"\n",
    "\n",
    "    def get_target_uri(self) -> str:\n",
    "\n",
    "        return f\"https://databus.dbpedia.org/{self.account_name}/{self.id}\"\n",
    "\n",
    "    def to_jsonld(self) -> str:\n",
    "        \"\"\"Generates the json representation of group documentation\"\"\"\n",
    "\n",
    "        group_uri = f\"https://databus.dbpedia.org/{self.account_name}/{self.id}\"\n",
    "\n",
    "        group_data_dict = {\n",
    "            \"@context\": self.context,\n",
    "            \"@graph\": [\n",
    "                {\n",
    "                    \"@id\": group_uri,\n",
    "                    \"@type\": \"Group\",\n",
    "                    \"label\": {\"@value\": self.label, \"@language\": \"en\"},\n",
    "                    \"title\": {\"@value\": self.title, \"@language\": \"en\"},\n",
    "                    \"comment\": {\"@value\": self.comment, \"@language\": \"en\"},\n",
    "                    \"abstract\": {\"@value\": self.abstract, \"@language\": \"en\"},\n",
    "                    \"description\": {\"@value\": self.description, \"@language\": \"en\"},\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "        return json.dumps(group_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabusFile:\n",
    "    def __init__(self, uri: str, cvs: dict, file_ext: str, **kwargs):\n",
    "        \"\"\"Fetches the necessary information of a file URI for the deploy to the databus.\"\"\"\n",
    "        self.uri = uri\n",
    "        self.cvs = cvs\n",
    "        resp = requests.get(uri, **kwargs)\n",
    "        if resp.status_code > 400:\n",
    "            print(f\"ERROR for {uri} -> Status {str(resp.status_code)}\")\n",
    "\n",
    "        self.sha256sum = hashlib.sha256(bytes(resp.content)).hexdigest()\n",
    "        self.content_length = str(len(resp.content))\n",
    "        self.file_ext = file_ext\n",
    "        self.id_string = \"_\".join([f\"{k}={v}\" for k, v in cvs.items()]) + \".\" + file_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataVersion:\n",
    "    account_name: str\n",
    "    group: str\n",
    "    artifact: str\n",
    "    version: str\n",
    "    title: str\n",
    "    label: str\n",
    "    publisher: str\n",
    "    comment: str\n",
    "    abstract: str\n",
    "    description: str\n",
    "    license: str\n",
    "    databus_files: List[DatabusFile]\n",
    "    issued: datetime = field(default_factory=datetime.now)\n",
    "    context: str = \"https://raw.githubusercontent.com/dbpedia/databus-git-mockup/main/dev/context.jsonld\"\n",
    "\n",
    "    def get_target_uri(self):\n",
    "\n",
    "        return f\"https://databus.dbpedia.org/{self.account_name}/{self.group}/{self.artifact}/{self.version}\"\n",
    "\n",
    "    def __distinct_cvs(self) -> dict:\n",
    "\n",
    "        distinct_cv_definitions = {}\n",
    "        for dbfile in self.databus_files:\n",
    "            for key, value in dbfile.cvs.items():\n",
    "\n",
    "                if key not in distinct_cv_definitions:\n",
    "                    distinct_cv_definitions[key] = {\n",
    "                        \"@type\": \"rdf:Property\",\n",
    "                        \"@id\": f\"dataid-cv:{key}\",\n",
    "                        \"rdfs:subPropertyOf\": {\"@id\": \"dataid:contentVariant\"},\n",
    "                    }\n",
    "        return distinct_cv_definitions\n",
    "\n",
    "    def __dbfiles_to_dict(self):\n",
    "\n",
    "        for dbfile in self.databus_files:\n",
    "            file_dst = {\n",
    "                \"@id\": self.version_uri + \"#\" + dbfile.id_string,\n",
    "                \"file\": self.version_uri + \"/\" + self.artifact + \"_\" + dbfile.id_string,\n",
    "                \"@type\": \"dataid:SingleFile\",\n",
    "                \"formatExtension\": dbfile.file_ext,\n",
    "                \"compression\": \"none\",\n",
    "                \"downloadURL\": dbfile.uri,\n",
    "                \"byteSize\": dbfile.content_length,\n",
    "                \"sha256sum\": dbfile.sha256sum,\n",
    "                \"hasVersion\": self.version,\n",
    "            }\n",
    "            for key, value in dbfile.cvs.items():\n",
    "\n",
    "                file_dst[f\"dataid-cv:{key}\"] = value\n",
    "\n",
    "            yield file_dst\n",
    "\n",
    "    def to_jsonld(self) -> str:\n",
    "        self.version_uri = (\n",
    "            f\"https://databus.dbpedia.org/{account_name}/{group}/{artifact}/{version}\"\n",
    "        )\n",
    "        self.data_id_uri = self.version_uri + \"#Dataset\"\n",
    "\n",
    "        self.artifact_uri = (\n",
    "            f\"https://databus.dbpedia.org/{account_name}/{group}/{artifact}\"\n",
    "        )\n",
    "\n",
    "        self.group_uri = f\"https://databus.dbpedia.org/{account_name}/{group}\"\n",
    "\n",
    "        self.timestamp = self.issued.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        data_id_dict = {\n",
    "            \"@context\": self.context,\n",
    "            \"@graph\": [\n",
    "                {\n",
    "                    \"@type\": \"dataid:Dataset\",\n",
    "                    \"@id\": self.data_id_uri,\n",
    "                    \"version\": self.version_uri,\n",
    "                    \"artifact\": self.artifact_uri,\n",
    "                    \"group\": self.group_uri,\n",
    "                    \"hasVersion\": self.version,\n",
    "                    \"issued\": self.timestamp,\n",
    "                    \"publisher\": self.publisher,\n",
    "                    \"label\": {\"@value\": self.label, \"@language\": \"en\"},\n",
    "                    \"title\": {\"@value\": self.title, \"@language\": \"en\"},\n",
    "                    \"comment\": {\"@value\": self.comment, \"@language\": \"en\"},\n",
    "                    \"abstract\": {\"@value\": self.abstract, \"@language\": \"en\"},\n",
    "                    \"description\": {\"@value\": self.description, \"@language\": \"en\"},\n",
    "                    \"license\": {\"@id\": self.license},\n",
    "                    \"distribution\": [d for d in self.__dbfiles_to_dict()],\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        for _, named_cv_prop in self.__distinct_cvs().items():\n",
    "            data_id_dict[\"@graph\"].append(named_cv_prop)\n",
    "\n",
    "        return json.dumps(data_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following needs a correct password, ask Leipzig for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_to_databus(user: str, passwd: str, *databus_objects):\n",
    "    try:\n",
    "        data = {\n",
    "            \"client_id\": \"upload-api\",\n",
    "            \"username\": \"lod-geoss\",\n",
    "            \"password\": \"XXXXXXXXXX\", #Enter correct password here\n",
    "            \"grant_type\": \"password\",\n",
    "        }\n",
    "\n",
    "        print(\"Accessing new token...\")\n",
    "        token_response = requests.post(\n",
    "            \"https://databus.dbpedia.org/auth/realms/databus/protocol/openid-connect/token\",\n",
    "            data=data,\n",
    "        )\n",
    "        print(f\"Response: Status {token_response.status_code}; Text: {token_response.text}\")\n",
    "\n",
    "        token = token_response.json()[\"access_token\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    for dbobj in databus_objects:\n",
    "\n",
    "        headers = {\"Authorization\": \"Bearer \" + token}\n",
    "\n",
    "        print(f\"Deploying {dbobj.get_target_uri()}\")\n",
    "        response = requests.put(\n",
    "            dbobj.get_target_uri(), headers=headers, data=dbobj.to_jsonld()\n",
    "        )\n",
    "        print(f\"Response: Status {response.status_code}; Text: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # account for publishing the dataset, password required\n",
    "    account_name = \"lod-geoss\" \n",
    "    group = \"OEP\"\n",
    "    artifact = \"KS95_emissions\" #inputdict[\"name\"]\n",
    "    version = \"2021-06-22\" #use_current_date\n",
    "    license = \"https://www.govdata.de/dl-de/by-2-0\" #inputdict[\"license_name\"]\n",
    "    publisher = \"https://raw.githubusercontent.com/LOD-GEOSS/databus-snippets/master/webid/webid.ttl#this\" #needs to change for new databus, ask leipzig\n",
    "    title = \"Overview of emissions from industrial processes of scenario KS95\" #inputdict[\"title\"]\n",
    "    label = \"KSz 2050\" #inputdict[\"keywords\"]\n",
    "    comment = \"...\" \n",
    "    abstract = \"... \" #inputdict[\"content_documentation\"]\n",
    "    description = \"...\" #inputdict[\"description\"]\n",
    "    files = [\n",
    "        DatabusFile(\n",
    "            \"https://openenergy-platform.org/api/v0/schema/scenario/tables/ksz2050_r2_ks95_co2_emissions_industrial_processes/rows/\",\n",
    "            {\"emissions\": \"ghg\"},\n",
    "            \"json\",\n",
    "        )# it's possible to add more files here after a comma\n",
    "    ]\n",
    "\n",
    "    databus_version = DataVersion(\n",
    "        account_name=account_name,\n",
    "        group=group,\n",
    "        artifact=artifact,\n",
    "        version=version,\n",
    "        title=title,\n",
    "        publisher=publisher,\n",
    "        label=label,\n",
    "        comment=comment,\n",
    "        abstract=abstract,\n",
    "        description=description,\n",
    "        license=license,\n",
    "        databus_files=files,\n",
    "    )\n",
    "\n",
    "    databus_group = DataGroup(\n",
    "        account_name=account_name,\n",
    "        id=group,\n",
    "        label=\"another1 LOD GEOSS Example\",\n",
    "        title=\"another2 LOD GEOSS Example\",\n",
    "        abstract=\"another3 Lorem ipsum dolor sit amet, consetetur sadipscing elitr.\",\n",
    "        comment=\"another4 Lorem ipsum dolor sit amet, consetetur sadipscing elitr.\",\n",
    "        description=\"another5 Lorem ipsum dolor sit amet, consetetur sadipscing elitr.\",\n",
    "    )\n",
    "\n",
    "    deploy_to_databus(\n",
    "        account_name, \"passwort\", databus_group, databus_version\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO write loop over schemas list to fetch all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO turn API call into function call with all tables -> register all OEP tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
